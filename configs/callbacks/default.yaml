learning_rate:
  _target_: lightning.pytorch.callbacks.LearningRateMonitor
  logging_interval: 'step'

checkpoint:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  every_n_epochs: 1
  save_top_k: -1  # Keep all checkpoints.
  filename: ${hydra:job.config_name}-{epoch:02d}-{val_loss:.6f}
